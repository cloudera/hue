{"body":"<div><div id=\"timestamp\"><div class=\"hue-doc-title\">TIMESTAMP Data Type</div><div><p>\n      In Impala, the <span class=\"hue-doc-codeph\">TIMESTAMP</span> data type holds a value of date and time. It can\n      be decomposed into year, month, day, hour, minute and seconds fields, but with no time\n      zone information available, it does not correspond to any specific point in time.\n    </p><p>\n      Internally, the resolution of the time portion of a <span class=\"hue-doc-codeph\">TIMESTAMP</span> value is in\n      nanoseconds.\n    </p><p id=\"syntax_blurb\"><b>Syntax:</b></p><p>\n      In the column definition of a <span class=\"hue-doc-codeph\">CREATE TABLE</span> statement:\n    </p><div class=\"hue-doc-codeblock\"><span class=\"hue-doc-varname\">column_name</span> TIMESTAMP\n\n<span class=\"hue-doc-varname\">timestamp</span> [+ | -] INTERVAL <span class=\"hue-doc-varname\">interval</span>\nDATE_ADD (<span class=\"hue-doc-varname\">timestamp</span>, INTERVAL <span class=\"hue-doc-varname\">interval</span><span class=\"hue-doc-varname\">time_unit</span>)</div><p><b>Range:</b> 1400-01-01 to 9999-12-31\n    </p><p>\n      Out of range <span class=\"hue-doc-codeph\">TIMESTAMP</span> values are converted to NULL.\n    </p><p>\n      The range of Impala <span class=\"hue-doc-codeph\">TIMESTAMP</span> is different from the Hive\n      <span class=\"hue-doc-codeph\">TIMESTAMP</span> type. Refer to\n      <a class=\"hue-doc-external-link\" href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types#LanguageManualTypes-timestamp\" target=\"_blank\">Hive\n      documentation</a> for detail.\n    </p><p><b>INTERVAL expressions:</b></p><p>\n      You can perform date arithmetic by adding or subtracting a specified number of time units,\n      using the <span class=\"hue-doc-codeph\">INTERVAL</span> keyword and the <span class=\"hue-doc-codeph\">+</span> operator, the\n      <span class=\"hue-doc-codeph\">-</span> operator, <span class=\"hue-doc-codeph\">date_add()</span> or <span class=\"hue-doc-codeph\">date_sub()</span>.\n    </p><p>\n      The following units are supported for <span class=\"hue-doc-codeph\"><i>time_unit</i></span> in the\n      <span class=\"hue-doc-codeph\">INTERVAL</span> clause:\n      <ul><li><span class=\"hue-doc-codeph\">YEAR[S]</span></li><li><span class=\"hue-doc-codeph\">MONTH[S]</span></li><li><span class=\"hue-doc-codeph\">WEEK[S]</span></li><li><span class=\"hue-doc-codeph\">DAY[S]</span></li><li><span class=\"hue-doc-codeph\">HOUR[S]</span></li><li><span class=\"hue-doc-codeph\">MINUTE[S]</span></li><li><span class=\"hue-doc-codeph\">SECOND[S]</span></li><li><span class=\"hue-doc-codeph\">MILLISECOND[S]</span></li><li><span class=\"hue-doc-codeph\">MICROSECOND[S]</span></li><li><span class=\"hue-doc-codeph\">NANOSECOND[S]</span></li></ul></p><p>\n      You can only specify one time unit in each interval expression, for example\n      <span class=\"hue-doc-codeph\">INTERVAL 3 DAYS</span> or <span class=\"hue-doc-codeph\">INTERVAL 25 HOURS</span>, but you can\n      produce any granularity by adding together successive <span class=\"hue-doc-codeph\">INTERVAL</span> values,\n      such as <span class=\"hue-doc-codeph\"><span class=\"hue-doc-varname\">timestamp_value</span> + INTERVAL 3 WEEKS - INTERVAL 1 DAY +\n      INTERVAL 10 MICROSECONDS</span>.\n    </p><p id=\"internals_16_bytes\"><b>Internal details:</b> Represented in memory as a 16-byte value.\n      </p><p><b>Time zones:</b></p><p>\n      By default, Impala stores and interprets <span class=\"hue-doc-codeph\">TIMESTAMP</span> values in UTC time\n      zone when writing to data files, reading from data files, or converting to and from system\n      time values through functions.\n    </p><p>\n      When you set the\n      <span class=\"hue-doc-codeph\">‑‑use_local_tz_for_unix_timestamp_conversions</span> startup flag to\n      <span class=\"hue-doc-codeph\">TRUE</span>, Impala treats the <span class=\"hue-doc-codeph\">TIMESTAMP</span> values specified in\n      the local time zone. The local time zone is determined in the following order with the\n      <span class=\"hue-doc-codeph\">TIMEZONE</span> query option takes the highest precedence:\n      <ol><li>\n          The <span class=\"hue-doc-codeph\">TIMEZONE</span> query option\n        </li><li><span class=\"hue-doc-codeph\">$TZ</span> environment variable\n        </li><li>\n          System time zone where the impalad coordinator runs\n        </li></ol></p><p>\n      The <span class=\"hue-doc-codeph\">‑‑use_local_tz_for_unix_timestamp_conversions</span> setting can\n      be used to fix discrepancy in <span class=\"hue-doc-codeph\">INTERVAL</span> operations. For example, a\n      <span class=\"hue-doc-codeph\">TIMESTAMP + INTERVAL <span class=\"hue-doc-varname\">n-hours</span></span> can be affected by\n      Daylight Saving Time, which Impala does not consider by default as these operations are\n      applied as if the timestamp was in UTC. You can use the\n      <span class=\"hue-doc-codeph\">--use_local_tz_for_unix_timestamp_conversions</span> setting to fix the issue.\n    </p><p>\n      See <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_custom_timezones.xml\" data-doc-anchor-id=\"custom_timezone\">Customizing Time Zones</a> for configuring to use\n      custom time zone database and aliases.\n    </p><p>\n      See <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_datetime_functions.xml\" data-doc-anchor-id=\"datetime_functions\">Impala Date and Time\n      Functions</a> for the list of functions affected by the\n      <span class=\"hue-doc-codeph\">--use_local_tz_for_unix_timestamp_conversions</span> setting.\n    </p><p><b>Time zone handling between Impala and Hive:</b></p><p>\n      Interoperability between Hive and Impala is different depending on the file format.\n    </p><ul><li><i>Text</i><p>\n          For text tables, <span class=\"hue-doc-codeph\">TIMESTAMP</span> values can be written and read\n          interchangeably by Impala and Hive as Hive reads and writes <span class=\"hue-doc-codeph\">TIMESTAMP</span>\n          values without converting with respect to time zones.\n        </p></li><li><i>Parquet</i><div class=\"hue-doc-note\">          This section only applies to <span class=\"hue-doc-codeph\">INT96 TIMESTAMP</span>. See\n          <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_parquet.xml\" data-doc-anchor-id=\"parquet_data_types\">Data Type Considerations for Parquet Tables</a> for information about Parquet\n          data types.\n        </div><p>\n          When Hive writes to Parquet data files, the <span class=\"hue-doc-codeph\">TIMESTAMP</span> values are\n          normalized to UTC from the local time zone of the host where the data was written. On\n          the other hand, Impala does not make any time zone adjustment when it writes or reads\n          <span class=\"hue-doc-codeph\">INT96 TIMESTAMP</span> values to Parquet files. This difference in time zone\n          handling can cause potentially inconsistent results when Impala processes\n          <span class=\"hue-doc-codeph\">TIMESTAMP</span> values in the Parquet files written by Hive.\n        </p><p>\n          To avoid incompatibility problems or having to code workarounds, you can specify one\n          or both of these impalad startup flags:\n          <ul><li><span class=\"hue-doc-codeph\">‑use_local_tz_for_unix_timestamp_conversions=true</span></li><li><span class=\"hue-doc-codeph\">‑convert_legacy_hive_parquet_utc_timestamps=true</span></li></ul></p><p>\n          When the <span class=\"hue-doc-codeph\">‑‑convert_legacy_hive_parquet_utc_timestamps</span>\n          setting is enabled, Impala recognizes the Parquet data files written by Hive, and\n          applies the same UTC-to-local-timezone conversion logic during the query as Hive does.\n        </p><p>\n          In Impala 3.0 and lower, the\n          <span class=\"hue-doc-codeph\">‑‑convert_legacy_hive_parquet_utc_timestamps</span> setting had a severe\n          impact on multi-threaded performance. The new time zone implementation in\n          Impala 3.1 eliminated most of the performance overhead and made\n          Impala scale well to multiple threads. The\n          <span class=\"hue-doc-codeph\">‑‑convert_legacy_hive_parquet_utc_timestamps</span> setting is turned\n          off by default for a performance reason. To avoid unexpected incompatibility problems,\n          you should turn on the option when processing <span class=\"hue-doc-codeph\">TIMESTAMP</span> columns in\n          Parquet files written by Hive.\n        </p><p>\n          Hive currently cannot write <span class=\"hue-doc-codeph\">INT64</span><span class=\"hue-doc-codeph\">TIMESTAMP</span> values.\n        </p><p>\n          In Impala 3.2 and higher, <span class=\"hue-doc-codeph\">INT64\n          TIMESTAMP</span> values annotated with the <span class=\"hue-doc-codeph\">TIMESTAMP_MILLIS</span> or\n          <span class=\"hue-doc-codeph\">TIMESTAMP_MICROS</span><span class=\"hue-doc-codeph\">OriginalType</span> are assumed to be\n          always UTC normalized, so the UTC to local conversion will be always done.\n          <span class=\"hue-doc-codeph\">INT64 TIMESTAMP</span> annotated with the <span class=\"hue-doc-codeph\">TIMESTAMP</span><span class=\"hue-doc-codeph\">LogicalType</span> specifies whether UTC to local conversion is necessary\n          depending on the Parquet metadata.\n        </p></li></ul><p><b>Conversions:</b></p><p id=\"timestamp_conversions\">\n        Impala automatically converts <span class=\"hue-doc-codeph\">STRING</span> literals of the correct format\n        into <span class=\"hue-doc-codeph\">TIMESTAMP</span> values. Timestamp values are accepted in the format\n        <span class=\"hue-doc-codeph\">'yyyy‑MM‑dd HH:mm:ss.SSSSSS'</span>, and can consist of just the date, or\n        just the time, with or without the fractional second portion. For example, you can\n        specify <span class=\"hue-doc-codeph\">TIMESTAMP</span> values such as <span class=\"hue-doc-codeph\">'1966‑07‑30'</span>,\n        <span class=\"hue-doc-codeph\">'08:30:00'</span>, or <span class=\"hue-doc-codeph\">'1985‑09‑25 17:45:30.005'</span>.\n      </p><p><span class=\"hue-doc-ph\" id=\"cast_int_to_timestamp\"> Casting an integer or floating-point value\n        <span class=\"hue-doc-codeph\">N</span> to <span class=\"hue-doc-codeph\">TIMESTAMP</span> produces a value that is\n        <span class=\"hue-doc-codeph\">N</span> seconds past the start of the epoch date (January 1, 1970). By\n        default, the result value represents a date and time in the UTC time zone. If the\n        setting <span class=\"hue-doc-codeph\">‑‑use_local_tz_for_unix_timestamp_conversions=true</span>\n        is in effect, the resulting <span class=\"hue-doc-codeph\">TIMESTAMP</span> represents a date and time in the\n        local time zone. </span></p><p>\n      In Impala 1.3 and higher, the <span class=\"hue-doc-codeph\">FROM_UNIXTIME()</span> and\n      <span class=\"hue-doc-codeph\">UNIX_TIMESTAMP()</span> functions allow a wider range of format strings, with\n      more flexibility in element order, repetition of letter placeholders, and separator\n      characters. In Impala 2.3 and higher, the\n      <span class=\"hue-doc-codeph\">UNIX_TIMESTAMP()</span> function also allows a numeric timezone offset to be\n      specified as part of the input string. See\n      <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_datetime_functions.xml\" data-doc-anchor-id=\"datetime_functions\">Impala Date and Time Functions</a> for details.\n    </p><p id=\"y2k38\">\n        In Impala 2.2.0 and higher, built-in functions that accept or return integers\n        representing <span class=\"hue-doc-codeph\">TIMESTAMP</span> values use the <span class=\"hue-doc-codeph\">BIGINT</span> type for\n        parameters and return values, rather than <span class=\"hue-doc-codeph\">INT</span>. This change lets the\n        date and time functions avoid an overflow error that would otherwise occur on January\n        19th, 2038 (known as the\n        <a class=\"hue-doc-external-link\" href=\"http://en.wikipedia.org/wiki/Year_2038_problem\" target=\"_blank\"><q>Year\n        2038 problem</q> or <q>Y2K38 problem</q></a>). This change affects the\n        <span class=\"hue-doc-codeph\">FROM_UNIXTIME()</span> and <span class=\"hue-doc-codeph\">UNIX_TIMESTAMP()</span> functions. You\n        might need to change application code that interacts with these functions, change the\n        types of columns that store the return values, or add <span class=\"hue-doc-codeph\">CAST()</span> calls to\n        SQL statements that call these functions.\n      </p><p><b>Partitioning:</b></p><p>\n      Although you cannot use a <span class=\"hue-doc-codeph\">TIMESTAMP</span> column as a partition key, you can\n      extract the individual years, months, days, hours, and so on and partition based on those\n      columns. Because the partition key column values are represented in HDFS directory names,\n      rather than as fields in the data files themselves, you can also keep the original\n      <span class=\"hue-doc-codeph\">TIMESTAMP</span> values if desired, without duplicating data or wasting storage\n      space. See <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_partitioning.xml\" data-doc-anchor-id=\"partition_key_columns\">Partition Key Columns</a> for more\n      details on partitioning with date and time values.\n    </p><div class=\"hue-doc-codeblock\">[localhost:21000] &gt; create table timeline (event string) partitioned by (happened timestamp);\nERROR: AnalysisException: Type 'TIMESTAMP' is not supported as partition-column type in column: happened\n</div><p id=\"null_bad_timestamp_cast\"><b>NULL considerations:</b> Casting any unrecognized <span class=\"hue-doc-codeph\">STRING</span> value to\n        this type produces a <span class=\"hue-doc-codeph\">NULL</span> value.\n      </p><p id=\"hbase_ok\"><b>HBase considerations:</b> This data type is fully compatible with HBase tables.\n      </p><p><b>Parquet consideration:</b><span class=\"hue-doc-codeph\">INT96</span> encoded Parquet timestamps are\n      supported in Impala. <span class=\"hue-doc-codeph\">INT64</span> timestamps are supported in\n      Impala 3.2 and higher.\n    </p><p/><p id=\"parquet_ok\"><b>Parquet considerations:</b> This type is fully compatible with Parquet tables.\n      </p><p id=\"text_bulky\"><b>Text table considerations:</b> Values of this type are potentially larger in text\n        tables than in tables using Parquet or other binary formats.\n      </p><p id=\"column_stats_constant\"><b>Column statistics considerations:</b> Because this type has a fixed size, the maximum\n        and average size fields are always filled in for column statistics, even before you run\n        the <span class=\"hue-doc-codeph\">COMPUTE STATS</span> statement.\n      </p><p id=\"kudu_blurb\"><b>Kudu considerations:</b></p><p id=\"kudu_timestamp_details\">\n        In Impala 2.9 and higher, you can include\n        <span class=\"hue-doc-codeph\">TIMESTAMP</span> columns in Kudu tables, instead of representing the date and\n        time as a <span class=\"hue-doc-codeph\">BIGINT</span> value. The behavior of <span class=\"hue-doc-codeph\">TIMESTAMP</span> for\n        Kudu tables has some special considerations:\n        <ul><li><p>\n              Any nanoseconds in the original 96-bit value produced by Impala are not stored,\n              because Kudu represents date/time columns using 64-bit values. The nanosecond\n              portion of the value is rounded, not truncated. Therefore, a\n              <span class=\"hue-doc-codeph\">TIMESTAMP</span> value that you store in a Kudu table might not be\n              bit-for-bit identical to the value returned by a query.\n            </p></li><li><p>\n              The conversion between the Impala 96-bit representation and the Kudu 64-bit\n              representation introduces some performance overhead when reading or writing\n              <span class=\"hue-doc-codeph\">TIMESTAMP</span> columns. You can minimize the overhead during writes by\n              performing inserts through the Kudu API. Because the overhead during reads applies\n              to each query, you might continue to use a <span class=\"hue-doc-codeph\">BIGINT</span> column to\n              represent date/time values in performance-critical applications.\n            </p></li><li><p>\n              The Impala <span class=\"hue-doc-codeph\">TIMESTAMP</span> type has a narrower range for years than the\n              underlying Kudu data type. Impala can represent years 1400-9999. If year values\n              outside this range are written to a Kudu table by a non-Impala client, Impala\n              returns <span class=\"hue-doc-codeph\">NULL</span> by default when reading those\n              <span class=\"hue-doc-codeph\">TIMESTAMP</span> values during a query. Or, if the\n              <span class=\"hue-doc-codeph\">ABORT_ON_ERROR</span> query option is enabled, the query fails when it\n              encounters a value with an out-of-range year.\n            </p></li></ul></p><p id=\"restrictions_blurb\"><b>Restrictions:</b></p><p>\n      If you cast a <span class=\"hue-doc-codeph\">STRING</span> with an unrecognized format to a\n      <span class=\"hue-doc-codeph\">TIMESTAMP</span>, the result is <span class=\"hue-doc-codeph\">NULL</span> rather than an error. Make\n      sure to test your data pipeline to be sure any textual date and time values are in a\n      format that Impala <span class=\"hue-doc-codeph\">TIMESTAMP</span> can recognize.\n    </p><p id=\"avro_no_timestamp\">\n        Currently, Avro tables cannot contain <span class=\"hue-doc-codeph\">TIMESTAMP</span> columns. If you need to\n        store date and time values in Avro tables, as a workaround you can use a\n        <span class=\"hue-doc-codeph\">STRING</span> representation of the values, convert the values to\n        <span class=\"hue-doc-codeph\">BIGINT</span> with the <span class=\"hue-doc-codeph\">UNIX_TIMESTAMP()</span> function, or create\n        separate numeric columns for individual date and time fields using the\n        <span class=\"hue-doc-codeph\">EXTRACT()</span> function.\n      </p><p id=\"example_blurb\"><b>Examples:</b></p><p>\n      The following examples demonstrate using <span class=\"hue-doc-codeph\">TIMESTAMP</span> values with built-in\n      functions:\n    </p><div class=\"hue-doc-codeblock\">select cast('1966-07-30' as timestamp);\nselect cast('1985-09-25 17:45:30.005' as timestamp);\nselect cast('08:30:00' as timestamp);\nselect hour('1970-01-01 15:30:00');         -- Succeeds, returns 15.\nselect hour('1970-01-01 15:30');            -- Returns NULL because seconds field required.\nselect hour('1970-01-01 27:30:00');         -- Returns NULL because hour value out of range.\nselect dayofweek('2004-06-13');             -- Returns 1, representing Sunday.\nselect dayname('2004-06-13');               -- Returns 'Sunday'.\nselect date_add('2004-06-13', 365);         -- Returns 2005-06-13 with zeros for hh:mm:ss fields.\nselect day('2004-06-13');                   -- Returns 13.\nselect datediff('1989-12-31','1984-09-01'); -- How many days between these 2 dates?\nselect now();                               -- Returns current date and time in local timezone.\n</div><p>\n      The following examples demonstrate using <span class=\"hue-doc-codeph\">TIMESTAMP</span> values with\n      HDFS-backed tables:\n    </p><div class=\"hue-doc-codeblock\">create table dates_and_times (t timestamp);\ninsert into dates_and_times values\n  ('1966-07-30'), ('1985-09-25 17:45:30.005'), ('08:30:00'), (now());\n</div><p>\n      The following examples demonstrate using <span class=\"hue-doc-codeph\">TIMESTAMP</span> values with Kudu\n      tables:\n    </p><div class=\"hue-doc-codeblock\">create table timestamp_t (x int primary key, s string, t timestamp, b bigint)\n  partition by hash (x) partitions 16\n  stored as kudu;\n\n-- The default value of now() has microsecond precision, so the final 3 digits\n-- representing nanoseconds are all zero.\ninsert into timestamp_t values (1, cast(now() as string), now(), unix_timestamp(now()));\n\n-- Values with 1-499 nanoseconds are rounded down in the Kudu TIMESTAMP column.\ninsert into timestamp_t values (2, cast(now() + interval 100 nanoseconds as string), now() + interval 100 nanoseconds, unix_timestamp(now() + interval 100 nanoseconds));\ninsert into timestamp_t values (3, cast(now() + interval 499 nanoseconds as string), now() + interval 499 nanoseconds, unix_timestamp(now() + interval 499 nanoseconds));\n\n-- Values with 500-999 nanoseconds are rounded up in the Kudu TIMESTAMP column.\ninsert into timestamp_t values (4, cast(now() + interval 500 nanoseconds as string), now() + interval 500 nanoseconds, unix_timestamp(now() + interval 500 nanoseconds));\ninsert into timestamp_t values (5, cast(now() + interval 501 nanoseconds as string), now() + interval 501 nanoseconds, unix_timestamp(now() + interval 501 nanoseconds));\n\n-- The string representation shows how underlying Impala TIMESTAMP can have nanosecond precision.\n-- The TIMESTAMP column shows how timestamps in a Kudu table are rounded to microsecond precision.\n-- The BIGINT column represents seconds past the epoch and so if not affected much by nanoseconds.\nselect s, t, b from timestamp_t order by t;\n+-------------------------------+-------------------------------+------------+\n| s                             | t                             | b          |\n+-------------------------------+-------------------------------+------------+\n| 2017-05-31 15:30:05.107157000 | 2017-05-31 15:30:05.107157000 | 1496244605 |\n| 2017-05-31 15:30:28.868151100 | 2017-05-31 15:30:28.868151000 | 1496244628 |\n| 2017-05-31 15:34:33.674692499 | 2017-05-31 15:34:33.674692000 | 1496244873 |\n| 2017-05-31 15:35:04.769166500 | 2017-05-31 15:35:04.769167000 | 1496244904 |\n| 2017-05-31 15:35:33.033082501 | 2017-05-31 15:35:33.033083000 | 1496244933 |\n+-------------------------------+-------------------------------+------------+\n</div><p id=\"added_forever\"><b>Added in:</b> Available in all versions of Impala.\n      </p><p id=\"related_info\"><b>Related information:</b></p><ul><li><a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_literals.xml\" data-doc-anchor-id=\"timestamp_literals\">Timestamp Literals</a>.\n      </li><li>\n        To convert to or from different date formats, or perform date arithmetic, use the date\n        and time functions described in\n        <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_datetime_functions.xml\" data-doc-anchor-id=\"datetime_functions\">Impala Date and Time Functions</a>. In\n        particular, the <span class=\"hue-doc-codeph\">from_unixtime()</span> function requires a case-sensitive\n        format string such as <span class=\"hue-doc-codeph\">\"yyyy-MM-dd HH:mm:ss.SSSS\"</span>, matching one of the\n        allowed variations of a <span class=\"hue-doc-codeph\">TIMESTAMP</span> value (date plus time, only date,\n        only time, optional fractional seconds).\n      </li><li>\n        See <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_langref_unsupported.xml\" data-doc-anchor-id=\"langref_hiveql_delta\">SQL Differences Between Impala and Hive</a> for\n        details about differences in <span class=\"hue-doc-codeph\">TIMESTAMP</span> handling between Impala and\n        Hive.\n      </li></ul></div></div></div>","title":"TIMESTAMP Data Type"}