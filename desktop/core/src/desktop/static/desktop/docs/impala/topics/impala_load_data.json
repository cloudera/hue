{"body":"<div><div id=\"load_data\"><div class=\"hue-doc-title\">LOAD DATA Statement</div><div><p> The <span class=\"hue-doc-codeph\">LOAD DATA</span> statement streamlines the ETL process for\n      an internal Impala table by moving a data file or all the data files in a\n      directory from an HDFS location into the Impala data directory for that\n      table. </p><p id=\"syntax_blurb\"><b>Syntax:</b></p><div class=\"hue-doc-codeblock\">LOAD DATA INPATH '<span class=\"hue-doc-varname\">hdfs_file_or_directory_path</span>' [OVERWRITE] INTO TABLE <span class=\"hue-doc-varname\">tablename</span>\n  [PARTITION (<span class=\"hue-doc-varname\">partcol1</span>=<span class=\"hue-doc-varname\">val1</span>, <span class=\"hue-doc-varname\">partcol2</span>=<span class=\"hue-doc-varname\">val2</span> ...)]</div><p>\n      When the <span class=\"hue-doc-codeph\">LOAD DATA</span> statement operates on a partitioned table,\n      it always operates on one partition at a time. Specify the <span class=\"hue-doc-codeph\">PARTITION</span> clauses\n      and list all the partition key columns, with a constant value specified for each.\n    </p><p id=\"dml_blurb\"><b>Statement type:</b> DML (but still affected by\n        <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_sync_ddl.xml\" data-doc-anchor-id=\"sync_ddl\">SYNC_DDL</a> query option)\n      </p><p id=\"usage_notes_blurb\"><b>Usage notes:</b></p><ul><li>\n        The loaded data files are moved, not copied, into the Impala data directory.\n      </li><li>\n        You can specify the HDFS path of a single file to be moved, or the HDFS path of a directory to move all the\n        files inside that directory. You cannot specify any sort of wildcard to take only some of the files from a\n        directory. When loading a directory full of data files, keep all the data files at the top level, with no\n        nested directories underneath.\n      </li><li>\n        Currently, the Impala <span class=\"hue-doc-codeph\">LOAD DATA</span> statement only imports files from HDFS, not from the local\n        filesystem. It does not support the <span class=\"hue-doc-codeph\">LOCAL</span> keyword of the Hive <span class=\"hue-doc-codeph\">LOAD DATA</span>\n        statement. You must specify a path, not an <span class=\"hue-doc-codeph\">hdfs://</span> URI.\n      </li><li>\n        In the interest of speed, only limited error checking is done. If the loaded files have the wrong file\n        format, different columns than the destination table, or other kind of mismatch, Impala does not raise any\n        error for the <span class=\"hue-doc-codeph\">LOAD DATA</span> statement. Querying the table afterward could produce a runtime\n        error or unexpected results. Currently, the only checking the <span class=\"hue-doc-codeph\">LOAD DATA</span> statement does is\n        to avoid mixing together uncompressed and LZO-compressed text files in the same table.\n      </li><li>\n        When you specify an HDFS directory name as the <span class=\"hue-doc-codeph\">LOAD DATA</span> argument, any hidden files in\n        that directory (files whose names start with a <span class=\"hue-doc-codeph\">.</span>) are not moved to the Impala data\n        directory.\n      </li><li>\n        The operation fails if the source directory contains any non-hidden directories.\n        Prior to Impala 2.5 if the source directory contained any subdirectory, even a hidden one such as\n        <span class=\"hue-doc-filepath\">_impala_insert_staging</span>, the <span class=\"hue-doc-codeph\">LOAD DATA</span> statement would fail.\n        In Impala 2.5 and higher, <span class=\"hue-doc-codeph\">LOAD DATA</span> ignores hidden subdirectories in the\n        source directory, and only fails if any of the subdirectories are non-hidden.\n      </li><li>\n        The loaded data files retain their original names in the new location, unless a name conflicts with an\n        existing data file, in which case the name of the new file is modified slightly to be unique. (The\n        name-mangling is a slight difference from the Hive <span class=\"hue-doc-codeph\">LOAD DATA</span> statement, which replaces\n        identically named files.)\n      </li><li>\n        By providing an easy way to transport files from known locations in HDFS into the Impala data directory\n        structure, the <span class=\"hue-doc-codeph\">LOAD DATA</span> statement lets you avoid memorizing the locations and layout of\n        HDFS directory tree containing the Impala databases and tables. (For a quick way to check the location of\n        the data files for an Impala table, issue the statement <span class=\"hue-doc-codeph\">DESCRIBE FORMATTED\n        <span class=\"hue-doc-varname\">table_name</span></span>.)\n      </li><li>\n        The <span class=\"hue-doc-codeph\">PARTITION</span> clause is especially convenient for ingesting new data for a partitioned\n        table. As you receive new data for a time period, geographic region, or other division that corresponds to\n        one or more partitioning columns, you can load that data straight into the appropriate Impala data\n        directory, which might be nested several levels down if the table is partitioned by multiple columns. When\n        the table is partitioned, you must specify constant values for all the partitioning columns.\n      </li></ul><p id=\"complex_types_blurb\"><b>Complex type considerations:</b></p><p>\n      Because Impala currently cannot create Parquet data files containing complex types\n      (<span class=\"hue-doc-codeph\">ARRAY</span>, <span class=\"hue-doc-codeph\">STRUCT</span>, and <span class=\"hue-doc-codeph\">MAP</span>), the\n      <span class=\"hue-doc-codeph\">LOAD DATA</span> statement is especially important when working with\n      tables containing complex type columns. You create the Parquet data files outside\n      Impala, then use either <span class=\"hue-doc-codeph\">LOAD DATA</span>, an external table, or HDFS-level\n      file operations followed by <span class=\"hue-doc-codeph\">REFRESH</span> to associate the data files with\n      the corresponding table.\n      See <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_complex_types.xml\" data-doc-anchor-id=\"complex_types\">Complex Types (Impala 2.3 or higher only)</a> for details about using complex types.\n    </p><p id=\"sync_ddl_blurb\">\n        If you connect to different Impala nodes within an <span class=\"hue-doc-cmdname\">impala-shell</span> session for\n        load-balancing purposes, you can enable the <span class=\"hue-doc-codeph\">SYNC_DDL</span> query option to make each DDL\n        statement wait before returning, until the new or changed metadata has been received by all the Impala\n        nodes. See <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_sync_ddl.xml\" data-doc-anchor-id=\"sync_ddl\">SYNC_DDL Query Option</a> for details.\n      </p><div class=\"hue-doc-note\" id=\"compute_stats_next\">        After adding or replacing data in a table used in performance-critical queries, issue a <span class=\"hue-doc-codeph\">COMPUTE\n        STATS</span> statement to make sure all statistics are up-to-date. Consider updating statistics for a\n        table after any <span class=\"hue-doc-codeph\">INSERT</span>, <span class=\"hue-doc-codeph\">LOAD DATA</span>, or <span class=\"hue-doc-codeph\">CREATE TABLE AS\n        SELECT</span> statement in Impala, or after loading data through Hive and doing a <span class=\"hue-doc-codeph\">REFRESH\n        <span class=\"hue-doc-varname\">table_name</span></span> in Impala. This technique is especially important for tables that\n        are very large, used in join queries, or both.\n      </div><p id=\"example_blurb\"><b>Examples:</b></p><p>\n      First, we use a trivial Python script to write different numbers of strings (one per line) into files stored\n      in the <span class=\"hue-doc-codeph\">doc_demo</span> HDFS user account. (Substitute the path for your own HDFS user account when\n      doing <span class=\"hue-doc-cmdname\">hdfs dfs</span> operations like these.)\n    </p><div class=\"hue-doc-codeblock\">$ random_strings.py 1000 | hdfs dfs -put - /user/doc_demo/thousand_strings.txt\n$ random_strings.py 100 | hdfs dfs -put - /user/doc_demo/hundred_strings.txt\n$ random_strings.py 10 | hdfs dfs -put - /user/doc_demo/ten_strings.txt</div><p>\n      Next, we create a table and load an initial set of data into it. Remember, unless you specify a\n      <span class=\"hue-doc-codeph\">STORED AS</span> clause, Impala tables default to <span class=\"hue-doc-codeph\">TEXTFILE</span> format with Ctrl-A (hex\n      01) as the field delimiter. This example uses a single-column table, so the delimiter is not significant. For\n      large-scale ETL jobs, you would typically use binary format data files such as Parquet or Avro, and load them\n      into Impala tables that use the corresponding file format.\n    </p><div class=\"hue-doc-codeblock\">[localhost:21000] &gt; create table t1 (s string);\n[localhost:21000] &gt; load data inpath '/user/doc_demo/thousand_strings.txt' into table t1;\nQuery finished, fetching results ...\n+----------------------------------------------------------+\n| summary                                                  |\n+----------------------------------------------------------+\n| Loaded 1 file(s). Total files in destination location: 1 |\n+----------------------------------------------------------+\nReturned 1 row(s) in 0.61s\n[kilo2-202-961.cs1cloud.internal:21000] &gt; select count(*) from t1;\nQuery finished, fetching results ...\n+------+\n| _c0  |\n+------+\n| 1000 |\n+------+\nReturned 1 row(s) in 0.67s\n[localhost:21000] &gt; load data inpath '/user/doc_demo/thousand_strings.txt' into table t1;\nERROR: AnalysisException: INPATH location '/user/doc_demo/thousand_strings.txt' does not exist. </div><p>\n      As indicated by the message at the end of the previous example, the data file was moved from its original\n      location. The following example illustrates how the data file was moved into the Impala data directory for\n      the destination table, keeping its original filename:\n    </p><div class=\"hue-doc-codeblock\">$ hdfs dfs -ls /user/hive/warehouse/load_data_testing.db/t1\nFound 1 items\n-rw-r--r--   1 doc_demo doc_demo      13926 2013-06-26 15:40 /user/hive/warehouse/load_data_testing.db/t1/thousand_strings.txt</div><p>\n      The following example demonstrates the difference between the <span class=\"hue-doc-codeph\">INTO TABLE</span> and\n      <span class=\"hue-doc-codeph\">OVERWRITE TABLE</span> clauses. The table already contains 1000 rows. After issuing the\n      <span class=\"hue-doc-codeph\">LOAD DATA</span> statement with the <span class=\"hue-doc-codeph\">INTO TABLE</span> clause, the table contains 100 more\n      rows, for a total of 1100. After issuing the <span class=\"hue-doc-codeph\">LOAD DATA</span> statement with the <span class=\"hue-doc-codeph\">OVERWRITE\n      INTO TABLE</span> clause, the former contents are gone, and now the table only contains the 10 rows from\n      the just-loaded data file.\n    </p><div class=\"hue-doc-codeblock\">[localhost:21000] &gt; load data inpath '/user/doc_demo/hundred_strings.txt' into table t1;\nQuery finished, fetching results ...\n+----------------------------------------------------------+\n| summary                                                  |\n+----------------------------------------------------------+\n| Loaded 1 file(s). Total files in destination location: 2 |\n+----------------------------------------------------------+\nReturned 1 row(s) in 0.24s\n[localhost:21000] &gt; select count(*) from t1;\nQuery finished, fetching results ...\n+------+\n| _c0  |\n+------+\n| 1100 |\n+------+\nReturned 1 row(s) in 0.55s\n[localhost:21000] &gt; load data inpath '/user/doc_demo/ten_strings.txt' overwrite into table t1;\nQuery finished, fetching results ...\n+----------------------------------------------------------+\n| summary                                                  |\n+----------------------------------------------------------+\n| Loaded 1 file(s). Total files in destination location: 1 |\n+----------------------------------------------------------+\nReturned 1 row(s) in 0.26s\n[localhost:21000] &gt; select count(*) from t1;\nQuery finished, fetching results ...\n+-----+\n| _c0 |\n+-----+\n| 10  |\n+-----+\nReturned 1 row(s) in 0.62s</div><p id=\"s3_blurb\"><b>Amazon S3 considerations:</b></p><p id=\"s3_dml\">\n        In Impala 2.6 and higher, the Impala DML statements (<span class=\"hue-doc-codeph\">INSERT</span>, <span class=\"hue-doc-codeph\">LOAD DATA</span>,\n        and <span class=\"hue-doc-codeph\">CREATE TABLE AS SELECT</span>) can write data into a table or partition that resides in the\n        Amazon Simple Storage Service (S3).\n        The syntax of the DML statements is the same as for any other tables, because the S3 location for tables and\n        partitions is specified by an <span class=\"hue-doc-codeph\">s3a://</span> prefix in the\n        <span class=\"hue-doc-codeph\">LOCATION</span> attribute of\n        <span class=\"hue-doc-codeph\">CREATE TABLE</span> or <span class=\"hue-doc-codeph\">ALTER TABLE</span> statements.\n        If you bring data into S3 using the normal S3 transfer mechanisms instead of Impala DML statements,\n        issue a <span class=\"hue-doc-codeph\">REFRESH</span> statement for the table before using Impala to query the S3 data.\n      </p><p id=\"s3_dml_performance\">\n        Because of differences between S3 and traditional filesystems, DML operations\n        for S3 tables can take longer than for tables on HDFS. For example, both the\n        <span class=\"hue-doc-codeph\">LOAD DATA</span> statement and the final stage of the <span class=\"hue-doc-codeph\">INSERT</span>\n        and <span class=\"hue-doc-codeph\">CREATE TABLE AS SELECT</span> statements involve moving files from one directory\n        to another. (In the case of <span class=\"hue-doc-codeph\">INSERT</span> and <span class=\"hue-doc-codeph\">CREATE TABLE AS SELECT</span>,\n        the files are moved from a temporary staging directory to the final destination directory.)\n        Because S3 does not support a <q>rename</q> operation for existing objects, in these cases Impala\n        actually copies the data files from one location to another and then removes the original files.\n        In Impala 2.6, the <span class=\"hue-doc-codeph\">S3_SKIP_INSERT_STAGING</span> query option provides a way\n        to speed up <span class=\"hue-doc-codeph\">INSERT</span> statements for S3 tables and partitions, with the tradeoff\n        that a problem during statement execution could leave data in an inconsistent state.\n        It does not apply to <span class=\"hue-doc-codeph\">INSERT OVERWRITE</span> or <span class=\"hue-doc-codeph\">LOAD DATA</span> statements.\n        See <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_s3_skip_insert_staging.xml\" data-doc-anchor-id=\"s3_skip_insert_staging\">S3_SKIP_INSERT_STAGING Query Option (Impala 2.6 or higher only)</a> for details.\n      </p><p>See <a class=\"hue-doc-external-link\" href=\"https://www.cloudera.com/documentation/enterprise/latest/topics/impala_s3.html#s3\" target=\"_blank\">Using Impala with the Amazon S3 Filesystem</a> for details about reading and writing S3 data with Impala.</p><p id=\"adls_blurb\"><b>ADLS considerations:</b></p><p id=\"adls_dml\"> In Impala 2.9 and higher, the Impala DML statements\n          (<span class=\"hue-doc-codeph\">INSERT</span>, <span class=\"hue-doc-codeph\">LOAD DATA</span>, and\n          <span class=\"hue-doc-codeph\">CREATE TABLE AS SELECT</span>) can write data into a table\n        or partition that resides in the Azure Data Lake Store (ADLS). ADLS Gen2\n        is supported in Impala 3.1 and higher.</p><p>See <a class=\"hue-doc-external-link\" href=\"https://www.cloudera.com/documentation/enterprise/latest/topics/impala_adls.html#adls\" target=\"_blank\">Using Impala with the Azure Data Lake Store (ADLS)</a> for details about reading and writing ADLS data with Impala.</p><p id=\"cancel_blurb_no\"><b>Cancellation:</b> Cannot be cancelled.\n      </p><p id=\"permissions_blurb\"><b>HDFS permissions:</b></p><p>\n      The user ID that the <span class=\"hue-doc-cmdname\">impalad</span> daemon runs under,\n      typically the <span class=\"hue-doc-codeph\">impala</span> user, must have read and write\n      permissions for the files in the source directory, and write\n      permission for the destination directory.\n    </p><p id=\"kudu_blurb\"><b>Kudu considerations:</b></p><p id=\"kudu_no_load_data\">\n        The <span class=\"hue-doc-codeph\">LOAD DATA</span> statement cannot be used with Kudu tables.\n      </p><p id=\"hbase_blurb\"><b>HBase considerations:</b></p><p id=\"hbase_no_load_data\">\n        The <span class=\"hue-doc-codeph\">LOAD DATA</span> statement cannot be used with HBase tables.\n      </p><p id=\"related_info\"><b>Related information:</b></p><p>\n      The <span class=\"hue-doc-codeph\">LOAD DATA</span> statement is an alternative to the\n      <span class=\"hue-doc-codeph\"><a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_insert.xml\" data-doc-anchor-id=\"insert\">INSERT</a></span> statement.\n      Use <span class=\"hue-doc-codeph\">LOAD DATA</span>\n      when you have the data files in HDFS but outside of any Impala table.\n    </p><p>\n      The <span class=\"hue-doc-codeph\">LOAD DATA</span> statement is also an alternative\n      to the <span class=\"hue-doc-codeph\">CREATE EXTERNAL TABLE</span> statement. Use\n      <span class=\"hue-doc-codeph\">LOAD DATA</span> when it is appropriate to move the\n      data files under Impala control rather than querying them\n      from their original location. See <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_tables.xml\" data-doc-anchor-id=\"external_tables\">External Tables</a>\n      for information about working with external tables.\n    </p></div></div></div>","title":"LOAD DATA Statement"}