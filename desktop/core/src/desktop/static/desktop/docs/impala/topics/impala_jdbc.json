{"body":"<div><div id=\"impala_jdbc\"><div class=\"hue-doc-title\" id=\"jdbc\">Configuring Impala to Work with JDBC</div><div><p> Impala supports the standard JDBC interface, allowing access from\n      commercial Business Intelligence tools and custom software written in Java\n      or other programming languages. The JDBC driver allows you to access\n      Impala from a Java program that you write, or a Business Intelligence or\n      similar tool that uses JDBC to communicate with various database products. </p><p> Setting up a JDBC connection to Impala involves the following steps: </p><ul><li> Verifying the communication port where the Impala daemons in your\n        cluster are listening for incoming JDBC requests. </li><li> Installing the JDBC driver on every system that runs the JDBC-enabled\n        application. </li><li> Specifying a connection string for the JDBC application to access one\n        of the servers running the <span class=\"hue-doc-cmdname\">impalad</span> daemon, with the\n        appropriate security settings. </li></ul><p/></div><div id=\"jdbc_port\"><div class=\"hue-doc-title\">Configuring the JDBC Port</div><div><p> The following are the default ports that Impala server accepts JDBC\n        connections through: <table id=\"simpletable_tr2_gnt_43b\"><tr><td><b>Protocol</b></td><td><b>Default Port</b></td><td><b>Flag to Specify an Alternate Port</b></td></tr><tr><td>HTTP</td><td>28000</td><td><span class=\"hue-doc-codeph\">‑‑hs2_http_port</span></td></tr><tr><td>Binary TCP</td><td>21050</td><td><span class=\"hue-doc-codeph\">‑‑hs2_port</span></td></tr></table></p><p> Make sure the port for the protocol you are using is available for\n        communication with clients, for example, that it is not blocked by\n        firewall software. </p><p> If your JDBC client software connects to a different port, specify\n        that alternative port number with the flag in the above table when\n        starting the <span class=\"hue-doc-codeph\">impalad</span>. </p></div></div><div id=\"jdbc_driver_choice\"><div class=\"hue-doc-title\">Choosing the JDBC Driver</div><div><p> In Impala 2.0 and later, you can use the Hive 0.13 or higher JDBC\n        driver. If you are already using JDBC applications with an earlier\n        Impala release, you should update your JDBC driver, because the Hive\n        0.12 driver that was formerly the only choice is not compatible with\n        Impala 2.0 and later. </p><p> The Hive JDBC driver provides a substantial speed increase for JDBC\n        applications with Impala 2.0 and higher, for queries that return large\n        result sets. </p></div></div><div id=\"jdbc_setup\"><div class=\"hue-doc-title\">Enabling Impala JDBC Support on Client Systems</div><div><div class=\"hue-doc-section\" id=\"install_hive_driver\"><div class=\"hue-doc-title\">Using the Hive JDBC Driver</div><p> You install the Hive JDBC driver (<span class=\"hue-doc-codeph\">hive-jdbc</span>\n          package) through the Linux package manager, on hosts within the\n          cluster. The driver consists of several JAR files. The same driver can\n          be used by Impala and Hive. </p><p> To get the JAR files, install the Hive JDBC driver on each host in\n          the cluster that will run JDBC applications.  </p><div class=\"hue-doc-note\"> The latest JDBC driver, corresponding to Hive 0.13, provides\n          substantial performance improvements for Impala queries that return\n          large result sets. Impala 2.0 and later are compatible with the Hive\n          0.13 driver. If you already have an older JDBC driver installed, and\n          are running Impala 2.0 or higher, consider upgrading to the latest\n          Hive JDBC driver for best performance with JDBC applications. </div><p> If you are using JDBC-enabled applications on hosts outside the\n          cluster, you cannot use the the same install procedure on the hosts.\n          Install the JDBC driver on at least one cluster host using the\n          preceding procedure. Then download the JAR files to each client\n          machine that will use JDBC with Impala: </p><div class=\"hue-doc-codeblock\">commons-logging-X.X.X.jar\n  hadoop-common.jar\n  hive-common-X.XX.X.jar\n  hive-jdbc-X.XX.X.jar\n  hive-metastore-X.XX.X.jar\n  hive-service-X.XX.X.jar\n  httpclient-X.X.X.jar\n  httpcore-X.X.X.jar\n  libfb303-X.X.X.jar\n  libthrift-X.X.X.jar\n  log4j-X.X.XX.jar\n  slf4j-api-X.X.X.jar\n  slf4j-logXjXX-X.X.X.jar\n  </div><p><b>To enable JDBC support for Impala on the system where you run the\n            JDBC application:</b></p><ol><li> Download the JAR files listed above to each client machine.\n              <div class=\"hue-doc-note\"> For Maven users, see <a class=\"hue-doc-external-link\" href=\"https://github.com/onefoursix/Cloudera-Impala-JDBC-Example\" target=\"_blank\">this sample github page</a> for an example of the\n              dependencies you could add to a <span class=\"hue-doc-codeph\">pom</span> file instead\n              of downloading the individual JARs. </div></li><li> Store the JAR files in a location of your choosing, ideally a\n            directory already referenced in your <span class=\"hue-doc-codeph\">CLASSPATH</span>\n            setting. For example: <ul><li> On Linux, you might use a location such as\n                  <span class=\"hue-doc-codeph\">/opt/jars/</span>. </li><li> On Windows, you might use a subdirectory underneath\n                  <span class=\"hue-doc-filepath\">C:\\Program Files</span>. </li></ul></li><li> To successfully load the Impala JDBC driver, client programs must\n            be able to locate the associated JAR files. This often means setting\n            the <span class=\"hue-doc-codeph\">CLASSPATH</span> for the client process to include the\n            JARs. Consult the documentation for your JDBC client for more\n            details on how to install new JDBC drivers, but some examples of how\n            to set <span class=\"hue-doc-codeph\">CLASSPATH</span> variables include: <ul><li> On Linux, if you extracted the JARs to\n                  <span class=\"hue-doc-codeph\">/opt/jars/</span>, you might issue the following\n                command to prepend the JAR files path to an existing classpath:\n                <div class=\"hue-doc-codeblock\">export CLASSPATH=/opt/jars/*.jar:$CLASSPATH</div></li><li> On Windows, use the <b>System Properties</b> control panel\n                item to modify the <b>Environment Variables</b> for your system.\n                Modify the environment variables to include the path to which\n                you extracted the files. <div class=\"hue-doc-note\"> If the existing\n                    <span class=\"hue-doc-codeph\">CLASSPATH</span> on your client machine refers to\n                  some older version of the Hive JARs, ensure that the new JARs\n                  are the first ones listed. Either put the new JAR files\n                  earlier in the listings, or delete the other references to\n                  Hive JAR files. </div></li></ul></li></ol></div></div></div><div id=\"jdbc_connect\"><div class=\"hue-doc-title\">Establishing JDBC Connections</div><div><p> The JDBC driver class depends on which driver you select. </p><div class=\"hue-doc-note\" id=\"proxy_jdbc_caveat\">        If your JDBC or ODBC application connects to Impala through a load balancer such as\n        <span class=\"hue-doc-codeph\">haproxy</span>, be cautious about reusing the connections. If the load\n        balancer has set up connection timeout values, either check the connection frequently so\n        that it never sits idle longer than the load balancer timeout value, or check the\n        connection validity before using it and create a new one if the connection has been\n        closed.\n      </div><div class=\"hue-doc-section\" id=\"class_hive_driver\"><div class=\"hue-doc-title\">Using the Hive JDBC Driver</div><p> For example, with the Hive JDBC driver, the class name is\n            <span class=\"hue-doc-codeph\">org.apache.hive.jdbc.HiveDriver</span>. Once you have\n          configured Impala to work with JDBC, you can establish connections\n          between the two. To do so for a cluster that does not use Kerberos\n          authentication, use a connection string of the form\n              <span class=\"hue-doc-codeph\">jdbc:hive2://<span class=\"hue-doc-varname\">host</span>:<span class=\"hue-doc-varname\">port</span>/;auth=noSasl</span>.\n          \n          For example, you might use: </p><div class=\"hue-doc-codeblock\">jdbc:hive2://myhost.example.com:21050/;auth=noSasl</div><p> To connect to an instance of Impala that requires Kerberos\n          authentication, use a connection string of the form\n              <span class=\"hue-doc-codeph\">jdbc:hive2://<span class=\"hue-doc-varname\">host</span>:<span class=\"hue-doc-varname\">port</span>/;principal=<span class=\"hue-doc-varname\">principal_name</span></span>.\n          The principal must be the same user principal you used when starting\n          Impala. For example, you might use: </p><div class=\"hue-doc-codeblock\">jdbc:hive2://myhost.example.com:21050/;principal=impala/myhost.example.com@H2.EXAMPLE.COM</div><p> To connect to an instance of Impala that requires LDAP\n          authentication, use a connection string of the form\n              <span class=\"hue-doc-codeph\">jdbc:hive2://<span class=\"hue-doc-varname\">host</span>:<span class=\"hue-doc-varname\">port</span>/<span class=\"hue-doc-varname\">db_name</span>;user=<span class=\"hue-doc-varname\">ldap_userid</span>;password=<span class=\"hue-doc-varname\">ldap_password</span></span>.\n          For example, you might use: </p><div class=\"hue-doc-codeblock\">jdbc:hive2://myhost.example.com:21050/test_db;user=fred;password=xyz123</div><p> To connect to an instance of Impala over HTTP, specify the HTTP\n          port, 28000 by default, and <span class=\"hue-doc-codeph\">transportMode=http</span> in the\n          connection string. For example:\n          <div class=\"hue-doc-codeblock\">jdbc:hive2://myhost.example.com:28000/;transportMode=http</div></p><div class=\"hue-doc-note\"><p id=\"hive_jdbc_ssl_kerberos_caveat\">\n        Prior to Impala 2.5, the Hive JDBC driver did not support\n        connections that use both Kerberos authentication and SSL encryption. If your cluster is\n        running an older release that has this restriction, use an alternative JDBC driver that\n        supports both of these security features.\n      </p></div></div></div></div><div id=\"jdbc_odbc_notes\"><div class=\"hue-doc-title\">Notes about JDBC and ODBC Interaction with Impala SQL\n      Features</div><div><p> Most Impala SQL features work equivalently through the\n          <span class=\"hue-doc-cmdname\">impala-shell</span> interpreter of the JDBC or ODBC APIs.\n        The following are some exceptions to keep in mind when switching between\n        the interactive shell and applications using the APIs: </p><ul><li><p id=\"complex_types_blurb\"><b>Complex type considerations:</b></p><ul><li><p> Queries involving the complex types (<span class=\"hue-doc-codeph\">ARRAY</span>,\n                  <span class=\"hue-doc-codeph\">STRUCT</span>, and <span class=\"hue-doc-codeph\">MAP</span>) require\n                notation that might not be available in all levels of JDBC and\n                ODBC drivers. If you have trouble querying such a table due to\n                the driver level or inability to edit the queries used by the\n                application, you can create a view that exposes a\n                  <q>flattened</q> version of the complex columns and point the\n                application at the view. See <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_complex_types.xml\" data-doc-anchor-id=\"complex_types\">Complex Types (Impala 2.3 or higher only)</a> for details.\n              </p></li><li><p> The complex types available in Impala 2.3 and higher are supported by the JDBC\n                  <span class=\"hue-doc-codeph\">getColumns()</span> API. Both <span class=\"hue-doc-codeph\">MAP</span>\n                and <span class=\"hue-doc-codeph\">ARRAY</span> are reported as the JDBC SQL Type\n                  <span class=\"hue-doc-codeph\">ARRAY</span>, because this is the closest matching\n                Java SQL type. This behavior is consistent with Hive.\n                  <span class=\"hue-doc-codeph\">STRUCT</span> types are reported as the JDBC SQL\n                Type <span class=\"hue-doc-codeph\">STRUCT</span>. </p><p> To be consistent with Hive's behavior, the TYPE_NAME field is\n                populated with the primitive type name for scalar types, and\n                with the full <span class=\"hue-doc-codeph\">toSql()</span> for complex types. The\n                resulting type names are somewhat inconsistent, because nested\n                types are printed differently than top-level types. For example,\n                the following list shows how <span class=\"hue-doc-codeph\">toSQL()</span> for Impala\n                types are translated to <span class=\"hue-doc-codeph\">TYPE_NAME</span> values: <div class=\"hue-doc-codeblock\">DECIMAL(10,10)         becomes  DECIMAL\nCHAR(10)               becomes  CHAR\nVARCHAR(10)            becomes  VARCHAR\nARRAY&lt;DECIMAL(10,10)&gt;  becomes  ARRAY&lt;DECIMAL(10,10)&gt;\nARRAY&lt;CHAR(10)&gt;        becomes  ARRAY&lt;CHAR(10)&gt;\nARRAY&lt;VARCHAR(10)&gt;     becomes  ARRAY&lt;VARCHAR(10)&gt;\n</div></p></li></ul></li></ul></div></div><div id=\"jdbc_kudu\"><div class=\"hue-doc-title\">Kudu Considerations for DML Statements</div><div><p> Currently, Impala <span class=\"hue-doc-codeph\">INSERT</span>, <span class=\"hue-doc-codeph\">UPDATE</span>, or\n        other DML statements issued through the JDBC interface against a Kudu\n        table do not return JDBC error codes for conditions such as duplicate\n        primary key columns. Therefore, for applications that issue a high\n        volume of DML statements, prefer to use the Kudu Java API directly\n        rather than a JDBC application. </p></div></div></div></div>","title":"Configuring Impala to Work with JDBC"}