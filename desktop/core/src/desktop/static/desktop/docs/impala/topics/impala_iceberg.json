{"body":"<div><div id=\"impala_iceberg\"><div class=\"hue-doc-title\" id=\"iceberg\">Using Impala with Iceberg Tables</div><div><p>\n      Impala now supports Apache Iceberg which is an open table format for huge analytic datasets.\n      With this functionality, you can access any existing Iceberg tables using SQL and perform\n      analytics over them. Using Impala you can create and write Iceberg tables in different\n      Iceberg Catalogs (e.g. HiveCatalog, HadoopCatalog). It also supports location-based\n      tables (HadoopTables).\n    </p><p>\n      Currently only Iceberg V1 DML operations are allowed, i.e. INSERT INTO /INSERT OVERWRITE.\n      Iceberg V2 operations like row-level modifications (UPDATE, DELETE) are not supported yet.\n    </p><p>\n      For more information on Iceberg, see <a class=\"hue-doc-external-link\" href=\"https://iceberg.apache.org\" target=\"_blank\">https://iceberg.apache.org</a>.\n    </p><p/></div><div id=\"iceberg_features\"><div class=\"hue-doc-title\">Overview of Iceberg features</div><div><ul><li>\n        ACID compliance: DML operations are atomic, queries always read a consistent snapshot.\n      </li><li>\n        Hidden partitioning: Iceberg produces partition values by taking a column value and\n        optionally transforming it. Partition information is stored in the Iceberg metadata\n        files. Iceberg is able to TRUNCATE column values or calculate\n        a hash of them and use it for partitioning. Readers don't need to be aware of the\n        partitioning of the table.\n      </li><li>\n        Partition layout evolution: When the data volume or the query patterns change you\n        can update the layout of a table. Since hidden partitioning is used, you don't need to\n        rewrite the data files during partition layout evolution.\n      </li><li>\n        Schema evolution: supports add, drop, update, or rename schema elements,\n        and has no side-effects.\n      </li><li>\n        Time travel: enables reproducible queries that use exactly the same table\n        snapshot, or lets users easily examine changes.\n      </li></ul></div></div><div id=\"iceberg_create\"><div class=\"hue-doc-title\">Creating Iceberg tables with Impala</div><div><p>\n        When you have an existing Iceberg table that is not yet present in the Hive Metastore,\n        you can use the <span class=\"hue-doc-codeph\">CREATE EXTERNAL TABLE</span> command in Impala to add the table to the Hive\n        Metastore and make Impala able to interact with this table. Currently Impala supports\n        HadoopTables, HadoopCatalog, and HiveCatalog. If you have an existing table in HiveCatalog,\n        and you are using the same Hive Metastore, you need no further actions.\n      </p><ul><li><b>HadoopTables</b>. When the table already exists in a HadoopTable it means there is\n          a location on the file system that contains your table. Use the following command\n          to add this table to Impala's catalog:\n          <div class=\"hue-doc-codeblock\">CREATE EXTERNAL TABLE ice_hadoop_tbl\nSTORED AS ICEBERG\nLOCATION '/path/to/table'\nTBLPROPERTIES('iceberg.catalog'='hadoop.tables');\n          </div></li><li><b>HadoopCatalog</b>. A table in HadoopCatalog means that there is a catalog location\n          in the file system under which Iceberg tables are stored. Use the following command\n          to add a table in a HadoopCatalog to Impala:\n          <div class=\"hue-doc-codeblock\">CREATE EXTERNAL TABLE ice_hadoop_cat\nSTORED AS ICEBERG\nTBLPROPERTIES('iceberg.catalog'='hadoop.catalog',\n              'iceberg.catalog_location'='/path/to/catalog',\n              'iceberg.table_identifier'='namespace.table');\n          </div></li><li>\n          Alternatively, you can also use custom catalogs to use existing tables. It means you need to define\n          your catalog in hive-site.xml.\n          The adventage of this method is that other engines are more likely to be able to interact with this table.\n          To globally register different catalogs, set the following Hadoop configurations:\n          <table id=\"iceberg_custom_catalogs\"><thead><tr><td>Config Key</td><td>Description</td></tr></thead><tbody><tr><td>iceberg.catalog.&lt;catalog_name&gt;.type</td><td>type of catalog: hive, hadoop, or left unset if using a custom catalog</td></tr><tr><td>iceberg.catalog.&lt;catalog_name&gt;.catalog-impl</td><td>catalog implementation, must not be null if type is empty</td></tr><tr><td>iceberg.catalog.&lt;catalog_name&gt;.&lt;key&gt;</td><td>any config key and value pairs for the catalog</td></tr></tbody></table><p>\n            For example, to register a HadoopCatalog called 'hadoop', set the following properties in hive-site.xml:\n            <div class=\"hue-doc-codeblock\">iceberg.catalog.hadoop.type=hadoop;\niceberg.catalog.hadoop.warehouse=hdfs://example.com:8020/warehouse;\n            </div></p><p>\n            Then in the CREATE TABLE statement you can just refer to the catalog name:\n            <div class=\"hue-doc-codeblock\">CREATE EXTERNAL TABLE ice_catalogs STORED AS ICEBERG TBLPROPERTIES('iceberg.catalog'='&lt;CATALOG-NAME&gt;');\n            </div></p></li><li>\n          If the table already exists in HiveCatalog then Impala should be able to see it without any additional\n          commands.\n        </li></ul><p>\n        You can also create new Iceberg tables with Impala. You can use the same commands as above, just\n        omit the <span class=\"hue-doc-codeph\">EXTERNAL</span> keyword. To create an Iceberg table in HiveCatalog the following\n        CREATE TABLE statement can be used:\n        <div class=\"hue-doc-codeblock\">CREATE TABLE ice_t (i INT) STORED AS ICEBERG;\n        </div></p><p>\n        By default Impala assumes that the Iceberg table uses Parquet data files. ORC is also supported,\n        but we need to tell Impala via setting the table property 'write.format.default' to 'ORC'.\n      </p><p>\n        You can also use <span class=\"hue-doc-codeph\">CREATE TABLE AS SELECT</span> to create new Iceberg tables, e.g.:\n        <div class=\"hue-doc-codeblock\">CREATE TABLE ice_ctas STORED AS ICEBERG AS SELECT i, b FROM value_tbl;\n\nCREATE TABLE ice_ctas_part PARTITIONED BY(d) STORED AS ICEBERG AS SELECT s, ts, d FROM value_tbl;\n\nCREATE TABLE ice_ctas_part_spec PARTITIONED BY SPEC (truncate(3, s)) STORED AS ICEBERG AS SELECT cast(t as INT), s, d FROM value_tbl;\n        </div></p></div></div><div id=\"iceberg_drop\"><div class=\"hue-doc-title\">Dropping Iceberg tables</div><div><p>\n        One can use <span class=\"hue-doc-codeph\">DROP TABLE</span> statement to remove an Iceberg table:\n        <div class=\"hue-doc-codeblock\">          DROP TABLE ice_t;\n        </div></p><p>\n        When <span class=\"hue-doc-codeph\">external.table.purge</span> table property is set to true, then the\n        <span class=\"hue-doc-codeph\">DROP TABLE</span> statement will also delete the data files. This property\n        is set to true when Impala creates the Iceberg table via <span class=\"hue-doc-codeph\">CREATE TABLE</span>.\n        When <span class=\"hue-doc-codeph\">CREATE EXTERNAL TABLE</span> is used (the table already exists in some\n        catalog) then this <span class=\"hue-doc-codeph\">external.table.purge</span> is set to false, i.e.\n        <span class=\"hue-doc-codeph\">DROP TABLE</span> doesn't remove any files, only the table definition\n        in HMS.\n      </p></div></div><div id=\"iceberg_types\"><div class=\"hue-doc-title\">Supported Data Types for Iceberg Columns</div><div><p>\n        You can get information about the supported Iceberg data tyeps in\n        <a class=\"hue-doc-external-link\" href=\"https://iceberg.apache.org/#spec/%23schemas-and-data-types\" target=\"_blank\">\n          the Iceberg spec</a>.\n      </p><p>\n        The Iceberg data types can be mapped to the following SQL types in Impala:\n        <table id=\"iceberg_types_sql_types\"><thead><tr><td>Iceberg type</td><td>SQL type in Impala</td></tr></thead><tbody><tr><td>boolean</td><td>BOOLEAN</td></tr><tr><td>int</td><td>INTEGER</td></tr><tr><td>long</td><td>BIGINT</td></tr><tr><td>float</td><td>FLOAT</td></tr><tr><td>double</td><td>DOUBLE</td></tr><tr><td>decimal(P, S)</td><td>DECIMAL(P, S)</td></tr><tr><td>date</td><td>DATE</td></tr><tr><td>time</td><td>Not supported</td></tr><tr><td>timestamp</td><td>TIMESTAMP</td></tr><tr><td>timestamptz</td><td>Only read support via TIMESTAMP</td></tr><tr><td>string</td><td>STRING</td></tr><tr><td>uuid</td><td>Not supported</td></tr><tr><td>fixed(L)</td><td>Not supported</td></tr><tr><td>binary</td><td>Not supported</td></tr><tr><td>struct</td><td>STRUCT (read only)</td></tr><tr><td>list</td><td>ARRAY (read only)</td></tr><tr><td>map</td><td>MAP (read only)</td></tr></tbody></table></p></div></div><div id=\"iceberg_schema_evolution\"><div class=\"hue-doc-title\">Schema evolution of Iceberg tables</div><div><p>\n        Iceberg assigns unique field ids to schema elements which means it is possible\n        to reorder/delete/change columns and still be able to correctly read current and\n        old data files. Impala supports the following statements to modify a table's schema:\n        <ul><li><span class=\"hue-doc-codeph\">ALTER TABLE ... RENAME TO ...</span> (renames the table if the Iceberg catalog supports it)</li><li><span class=\"hue-doc-codeph\">ALTER TABLE ... CHANGE COLUMN ...</span> (change name and type of a column iff the new type is compatible with the old type)</li><li><span class=\"hue-doc-codeph\">ALTER TABLE ... ADD COLUMNS ...</span> (adds columns to the end of the table)</li><li><span class=\"hue-doc-codeph\">ALTER TABLE ... DROP COLUMN ...</span></li></ul></p><p>\n        Valid type promotions are:\n        <ul><li>int to long</li><li>float to double</li><li>decimal(P, S) to decimal(P', S) if P' &gt; P â€“ widen the precision of decimal types.</li></ul></p><p>\n        See\n        <a class=\"hue-doc-external-link\" href=\"https://iceberg.apache.org/#spec/%23schema-evolution\" target=\"_blank\">\n        schema evolution </a> for more details.\n      </p></div></div><div id=\"iceberg_partitioning\"><div class=\"hue-doc-title\">Partitioning Iceberg tables</div><div><p><a class=\"hue-doc-external-link\" href=\"https://iceberg.apache.org/#spec/%23partitioning\" target=\"_blank\">\n        The Iceberg spec </a> has information about partitioning Iceberg tables. With Iceberg,\n        we are not limited to value-based partitioning, we can also partition our tables via\n        several partition transforms.\n      </p><p>\n        Partition transforms are IDENTITY, BUCKET, TRUNCATE, YEAR, MONTH, DAY, HOUR, and VOID.\n        Impala supports all of these transforms. To create a partitioned Iceberg table, one\n        needs to add a <span class=\"hue-doc-codeph\">PARTITIONED BY SPEC</span> clause to the CREATE TABLE statement, e.g.:\n        <div class=\"hue-doc-codeblock\">CREATE TABLE ice_p (i INT, d DATE, s STRING, t TIMESTAMP)\nPARTITIONED BY SPEC (BUCKET(5, i), MONTH(d), TRUNCATE(3, s), HOUR(t))\nSTORED AS ICEBERG;\n        </div></p><p>\n        Iceberg also supports\n        <a class=\"hue-doc-external-link\" href=\"https://iceberg.apache.org/#spec/%23partition-evolution\" target=\"_blank\">\n        partition evolution</a> which means that the partitioning of a table can be changed, even\n        without the need of rewriting existing data files. You can change an existing table's\n        partitioning via an <span class=\"hue-doc-codeph\">ALTER TABLE SET PARTITION SPEC</span> statement, e.g.:\n        <div class=\"hue-doc-codeblock\">ALTER TABLE ice_p SET PARTITION SPEC (VOID(i), VOID(d), TRUNCATE(3, s), HOUR(t), i);\n        </div></p><p>\n        Please keep in mind that for Iceberg V1 tables:\n        <ul><li>Do not reorder partition fields</li><li>Do not drop partition fields; instead replace the fieldâ€™s transform with the void transform</li><li>Only add partition fields at the end of the previous partition spec</li></ul></p><p>\n        You can also use the legacy syntax to create identity-partitioned Iceberg tables:\n        <div class=\"hue-doc-codeblock\">CREATE TABLE ice_p (i INT, b INT) PARTITIONED BY (p1 INT, p2 STRING) STORED AS ICEBERG;\n        </div></p><p>\n        One can inspect a table's partition spec by the <span class=\"hue-doc-codeph\">SHOW PARTITIONS</span> or\n        <span class=\"hue-doc-codeph\">SHOW CREATE TABLE</span> commands.\n      </p></div></div><div id=\"iceberg_inserts\"><div class=\"hue-doc-title\">Writing Iceberg tables</div><div><p>\n        Impala is also able to insert new data to Iceberg tables. Currently the <span class=\"hue-doc-codeph\">INSERT INTO</span>\n        and <span class=\"hue-doc-codeph\">INSERT OVERWRITE</span> DML statements are supported. One can also remove the\n        contents of an Iceberg table via the <span class=\"hue-doc-codeph\">TRUNCATE</span> command.\n      </p><p>\n        Since Iceberg uses hidden partitioning it means you don't need a partition clause in your INSERT\n        statements. E.g. insertion to a partitioned table looks like:\n        <div class=\"hue-doc-codeblock\">CREATE TABLE ice_p (i INT, b INT) PARTITIONED BY SPEC (bucket(17, i)) STORED AS ICEBERG;\nINSERT INTO ice_p VALUES (1, 2);\n        </div></p><p><span class=\"hue-doc-codeph\">INSERT OVERWRITE</span> statements can replace data in the table with the result of a query.\n        For partitioned tables Impala does a dynamic overwrite, which means partitions that have rows produced\n        by the SELECT query will be replaced. And partitions that have no rows produced by the SELECT query\n        remain untouched. INSERT OVERWRITE is not allowed for tables that use the BUCKET partition transform\n        because dynamic overwrite behavior would be too random in this case. If one needs to replace all\n        contents of a table, they can still use <span class=\"hue-doc-codeph\">TRUNCATE</span> and <span class=\"hue-doc-codeph\">INSERT INTO</span>.\n      </p><p>\n        Impala can only write Iceberg tables with Parquet data files.\n      </p></div></div><div id=\"iceberg_time_travel\"><div class=\"hue-doc-title\">Time travel for Iceberg tables</div><div><p>\n        Iceberg stores the table states in a chain of snapshots. By default, Impala uses the current\n        snapshot of the table. But for Iceberg tables, it is also possible to query an earlier state of\n        the table.\n      </p><p>\n        We can use the <span class=\"hue-doc-codeph\">FOR SYSTEM_TIME AS OF</span> and <span class=\"hue-doc-codeph\">FOR SYSTEM_VERSION AS OF</span>\n        clauses in <span class=\"hue-doc-codeph\">SELECT</span> queries, e.g.:\n        <div class=\"hue-doc-codeblock\">SELECT * FROM ice_t FOR SYSTEM_TIME AS OF '2022-01-04 10:00:00';\nSELECT * FROM ice_t FOR SYSTEM_TIME AS OF now() - interval 5 days;\nSELECT * FROM ice_t FOR SYSTEM_VERSION AS OF 123456;\n        </div></p><p>\n        If one needs to check the available snapshots of a table they can use the <span class=\"hue-doc-codeph\">DESCRIBE HISTORY</span>\n        statement with the following syntax:\n        <div class=\"hue-doc-codeblock\">DESCRIBE HISTORY [<span class=\"hue-doc-varname\">db_name</span>.]<span class=\"hue-doc-varname\">table_name</span>\n  [FROM <span class=\"hue-doc-varname\">timestamp</span>];\n\nDESCRIBE HISTORY [<span class=\"hue-doc-varname\">db_name</span>.]<span class=\"hue-doc-varname\">table_name</span>\n  [BETWEEN <span class=\"hue-doc-varname\">timestamp</span> AND <span class=\"hue-doc-varname\">timestamp</span>]\n        </div>\n        For example:\n<div class=\"hue-doc-codeblock\">DESCRIBE HISTORY ice_t FROM '2022-01-04 10:00:00';\nDESCRIBE HISTORY ice_t FROM now() - interval 5 days;\nDESCRIBE HISTORY ice_t BETWEEN '2022-01-04 10:00:00' AND '2022-01-05 10:00:00';\n</div></p><p>\n        Please note that during time travel, Impala uses the current table schema to query an older\n        snapshot of the table which might have had a different schema in the past.\n      </p></div></div><div id=\"iceberg_table_properties\"><div class=\"hue-doc-title\">Iceberg table properties</div><div><p>\n        We can set the following table properties for Iceberg tables:\n        <ul><li><span class=\"hue-doc-codeph\">iceberg.catalog</span>: controls which catalog is used for this Iceberg table.\n            It can be 'hive.catalog' (default), 'hadoop.catalog', 'hadoop.tables', or a name that\n            identifies a catalog defined in the Hadoop configurations, e.g. hive-site.xml\n          </li><li><span class=\"hue-doc-codeph\">iceberg.catalog_location</span>: Iceberg table catalog location when <span class=\"hue-doc-codeph\">iceberg.catalog</span> is <span class=\"hue-doc-codeph\">'hadoop.catalog'</span></li><li><span class=\"hue-doc-codeph\">iceberg.table_identifier</span>: Iceberg table identifier. We use &lt;database&gt;.&lt;table&gt; instead if this property is not set</li><li><span class=\"hue-doc-codeph\">write.format.default</span>: data file format of the table. Impala can read ORC and PARQUET data files in Iceberg tables, and can write PARQUET data files only.</li><li><span class=\"hue-doc-codeph\">write.parquet.compression-codec</span>:\n            Parquet compression codec. Supported values are: NONE, GZIP, SNAPPY\n            (default value), LZ4, ZSTD. The table property will be ignored if\n            <span class=\"hue-doc-codeph\">COMPRESSION_CODEC</span> query option is set.\n          </li><li><span class=\"hue-doc-codeph\">write.parquet.compression-level</span>:\n            Parquet compression level. Used with ZSTD compression only.\n            Supported range is [1, 22]. Default value is 3. The table property\n            will be ignored if <span class=\"hue-doc-codeph\">COMPRESSION_CODEC</span> query option is set.\n          </li><li><span class=\"hue-doc-codeph\">write.parquet.row-group-size-bytes</span>:\n            Parquet row group size in bytes. Supported range is [8388608,\n            2146435072] (8MB - 2047MB). The table property will be ignored if\n            <span class=\"hue-doc-codeph\">PARQUET_FILE_SIZE</span> query option is set.\n            If neither the table property nor the <span class=\"hue-doc-codeph\">PARQUET_FILE_SIZE</span> query option\n            is set, the way Impala calculates row group size will remain\n            unchanged.\n          </li><li><span class=\"hue-doc-codeph\">write.parquet.page-size-bytes</span>:\n            Parquet page size in bytes. Used for PLAIN encoding. Supported range\n            is [65536, 1073741824] (64KB - 1GB).\n            If the table property is unset, the way Impala calculates page size\n            will remain unchanged.\n          </li><li><span class=\"hue-doc-codeph\">write.parquet.dict-size-bytes</span>:\n            Parquet dictionary page size in bytes. Used for dictionary encoding.\n            Supported range is [65536, 1073741824] (64KB - 1GB).\n            If the table property is unset, the way Impala calculates dictionary\n            page size will remain unchanged.\n          </li></ul></p></div></div></div></div>","title":"Using Impala with Iceberg Tables"}