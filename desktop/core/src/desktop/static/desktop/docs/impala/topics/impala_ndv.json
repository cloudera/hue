{"body":"<div><div id=\"ndv\"><div class=\"hue-doc-title\">NDV Function</div><div><p>\n      An aggregate function that returns an approximate value similar to the result of <span class=\"hue-doc-codeph\">COUNT(DISTINCT\n      <span class=\"hue-doc-varname\">col</span>)</span>, the <q>number of distinct values</q>. It is much faster than the\n      combination of <span class=\"hue-doc-codeph\">COUNT</span> and <span class=\"hue-doc-codeph\">DISTINCT</span>, and uses a constant amount of memory and\n      thus is less memory-intensive for columns with high cardinality.\n    </p><p id=\"syntax_blurb\"><b>Syntax:</b></p><div class=\"hue-doc-codeblock\">NDV([DISTINCT | ALL] <span class=\"hue-doc-varname\">expression</span> [,scale])</div><div class=\"hue-doc-note\"> The optional argument <span class=\"hue-doc-codeph\">scale</span> must be an integer and can be in the range\n      from 1 to 10 and maps to a precision used by the HyperLogLog (HLL) algorithm with the\n      following mapping formula:</div><p><div class=\"hue-doc-codeblock\">precision = scale + 8</div></p><p>\n      Therefore a scale of 1 is mapped to a precision of 9 and a scale of 10 is mapped to a\n      precision of 18.\n    </p><p>\n      Without the optional argument, the precision which determines the total number\n      of different estimators in the HLL algorithm will be still 10.\n    </p><p>\n      A large precision value generally produces a better estimation with less error than a small\n      precision value. This is due to the extra number of estimators involved. The expense is at the\n      need of extra memory. For a given precision p, the amount of memory used by the HLL algorithm\n      is in the order of 2^p bytes.\n    </p><p>\n      When provided a scale of 10 against a total of 22 distinct data sets loaded into external\n      Impala tables, the error will be computed as\n      abs(&lt;true_unique_value&gt; - &lt;estimated_unique_value&gt;) / &lt;true_unique_value&gt;\n    </p><p>\n      The scale of 10, mapped to the precision of 18, yielded the worst estimation error at 0.42%\n      (for one set of 10 million integers), and average error no more than 0.17%. This was at the\n      cost of 256Kb of memory for the internal data structure per evaluation of the HLL algorithm.\n    </p><p id=\"usage_notes_blurb\"><b>Usage notes:</b></p><p>\n      This is the mechanism used internally by the <span class=\"hue-doc-codeph\">COMPUTE STATS</span> statement for computing the\n      number of distinct values in a column.\n    </p><p>\n      Because this number is an estimate, it might not reflect the precise number of different values in the\n      column, especially if the cardinality is very low or very high. If the estimated number is higher than the\n      number of rows in the table, Impala adjusts the value internally during query planning.\n    </p><p id=\"former_odd_return_type_string\"><b>Return type:</b><span class=\"hue-doc-codeph\">DOUBLE</span> in Impala 2.0 and higher;\n        <span class=\"hue-doc-codeph\">STRING</span> in earlier releases\n      </p><p id=\"complex_types_blurb\"><b>Complex type considerations:</b></p><p id=\"complex_types_aggregation_explanation\">\n        To access a column with a complex type (<span class=\"hue-doc-codeph\">ARRAY</span>, <span class=\"hue-doc-codeph\">STRUCT</span>,\n        or <span class=\"hue-doc-codeph\">MAP</span>) in an aggregation function, you unpack the individual elements\n        using join notation in the query, and then apply the function to the final scalar item,\n        field, key, or value at the bottom of any nested type hierarchy in the column. See\n        <a class=\"hue-doc-internal-link\" href=\"javascript:void(0);\" data-doc-ref=\"topics/impala_complex_types.xml\" data-doc-anchor-id=\"complex_types\">Complex Types (Impala 2.3 or higher only)</a> for details about using\n        complex types in Impala.\n      </p><p id=\"complex_types_aggregation_example\">\n        The following example demonstrates calls to several aggregation functions using values\n        from a column containing nested complex types (an <span class=\"hue-doc-codeph\">ARRAY</span> of\n        <span class=\"hue-doc-codeph\">STRUCT</span> items). The array is unpacked inside the query using join\n        notation. The array elements are referenced using the <span class=\"hue-doc-codeph\">ITEM</span>\n        pseudocolumn, and the structure fields inside the array elements are referenced using\n        dot notation. Numeric values such as <span class=\"hue-doc-codeph\">SUM()</span> and <span class=\"hue-doc-codeph\">AVG()</span>\n        are computed using the numeric <span class=\"hue-doc-codeph\">R_NATIONKEY</span> field, and the\n        general-purpose <span class=\"hue-doc-codeph\">MAX()</span> and <span class=\"hue-doc-codeph\">MIN()</span> values are computed\n        from the string <span class=\"hue-doc-codeph\">N_NAME</span> field.\n<div class=\"hue-doc-codeblock\">describe region;\n+-------------+-------------------------+---------+\n| name        | type                    | comment |\n+-------------+-------------------------+---------+\n| r_regionkey | smallint                |         |\n| r_name      | string                  |         |\n| r_comment   | string                  |         |\n| r_nations   | array&lt;struct&lt;           |         |\n|             |   n_nationkey:smallint, |         |\n|             |   n_name:string,        |         |\n|             |   n_comment:string      |         |\n|             | &gt;&gt;                      |         |\n+-------------+-------------------------+---------+\n\nselect r_name, r_nations.item.n_nationkey\n  from region, region.r_nations as r_nations\norder by r_name, r_nations.item.n_nationkey;\n+-------------+------------------+\n| r_name      | item.n_nationkey |\n+-------------+------------------+\n| AFRICA      | 0                |\n| AFRICA      | 5                |\n| AFRICA      | 14               |\n| AFRICA      | 15               |\n| AFRICA      | 16               |\n| AMERICA     | 1                |\n| AMERICA     | 2                |\n| AMERICA     | 3                |\n| AMERICA     | 17               |\n| AMERICA     | 24               |\n| ASIA        | 8                |\n| ASIA        | 9                |\n| ASIA        | 12               |\n| ASIA        | 18               |\n| ASIA        | 21               |\n| EUROPE      | 6                |\n| EUROPE      | 7                |\n| EUROPE      | 19               |\n| EUROPE      | 22               |\n| EUROPE      | 23               |\n| MIDDLE EAST | 4                |\n| MIDDLE EAST | 10               |\n| MIDDLE EAST | 11               |\n| MIDDLE EAST | 13               |\n| MIDDLE EAST | 20               |\n+-------------+------------------+\n\nselect\n  r_name,\n  count(r_nations.item.n_nationkey) as count,\n  sum(r_nations.item.n_nationkey) as sum,\n  avg(r_nations.item.n_nationkey) as avg,\n  min(r_nations.item.n_name) as minimum,\n  max(r_nations.item.n_name) as maximum,\n  ndv(r_nations.item.n_nationkey) as distinct_vals\nfrom\n  region, region.r_nations as r_nations\ngroup by r_name\norder by r_name;\n+-------------+-------+-----+------+-----------+----------------+---------------+\n| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |\n+-------------+-------+-----+------+-----------+----------------+---------------+\n| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |\n| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |\n| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |\n| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |\n| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |\n+-------------+-------+-----+------+-----------+----------------+---------------+\n</div></p><p id=\"restrictions_blurb\"><b>Restrictions:</b></p><p id=\"analytic_not_allowed_caveat\">\n        This function cannot be used in an analytic context. That is, the\n        <span class=\"hue-doc-codeph\">OVER()</span> clause is not allowed at all with this function.\n      </p><p id=\"example_blurb\"><b>Examples:</b></p><p>\n      The following example queries a billion-row table to illustrate the relative performance of\n      <span class=\"hue-doc-codeph\">COUNT(DISTINCT)</span> and <span class=\"hue-doc-codeph\">NDV()</span>. It shows how <span class=\"hue-doc-codeph\">COUNT(DISTINCT)</span>\n      gives a precise answer, but is inefficient for large-scale data where an approximate result is sufficient.\n      The <span class=\"hue-doc-codeph\">NDV()</span> function gives an approximate result but is much faster.\n    </p><div class=\"hue-doc-codeblock\">select count(distinct col1) from sample_data;\n+---------------------+\n| count(distinct col1)|\n+---------------------+\n| 100000              |\n+---------------------+\nFetched 1 row(s) in 20.13s\n\nselect cast(ndv(col1) as bigint) as col1 from sample_data;\n+----------+\n| col1     |\n+----------+\n| 139017   |\n+----------+\nFetched 1 row(s) in 8.91s\n</div><p>\n      The following example shows how you can code multiple <span class=\"hue-doc-codeph\">NDV()</span> calls in a single query, to\n      easily learn which columns have substantially more or fewer distinct values. This technique is faster than\n      running a sequence of queries with <span class=\"hue-doc-codeph\">COUNT(DISTINCT)</span> calls.\n    </p><div class=\"hue-doc-codeblock\">select cast(ndv(col1) as bigint) as col1, cast(ndv(col2) as bigint) as col2,\n    cast(ndv(col3) as bigint) as col3, cast(ndv(col4) as bigint) as col4\n  from sample_data;\n+----------+-----------+------------+-----------+\n| col1     | col2      | col3       | col4      |\n+----------+-----------+------------+-----------+\n| 139017   | 282       | 46         | 145636240 |\n+----------+-----------+------------+-----------+\nFetched 1 row(s) in 34.97s\n\nselect count(distinct col1) from sample_data;\n+---------------------+\n| count(distinct col1)|\n+---------------------+\n| 100000              |\n+---------------------+\nFetched 1 row(s) in 20.13s\n\nselect count(distinct col2) from sample_data;\n+----------------------+\n| count(distinct col2) |\n+----------------------+\n| 278                  |\n+----------------------+\nFetched 1 row(s) in 20.09s\n\nselect count(distinct col3) from sample_data;\n+-----------------------+\n| count(distinct col3)  |\n+-----------------------+\n| 46                    |\n+-----------------------+\nFetched 1 row(s) in 19.12s\n\nselect count(distinct col4) from sample_data;\n+----------------------+\n| count(distinct col4) |\n+----------------------+\n| 147135880            |\n+----------------------+\nFetched 1 row(s) in 266.95s\n</div></div></div></div>","title":"NDV Function"}