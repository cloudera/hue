[
  {
    "name": "Sample: Salary Analysis",
    "desc": "Top salary 2007 above $100k, Salary growth (sorted) from 2007-08",
    "dialects": [
      "postgresql",
      "mysql",
      "presto"
    ],
    "data": {
      "query": {
        "statement": "SELECT sample_07.description, sample_07.salary\r\nFROM\r\n  sample_07\r\nWHERE\r\n( sample_07.salary > 100000)\r\nORDER BY sample_07.salary DESC\r\nLIMIT 1000;\n\n\nSELECT s07.description, s07.salary, s08.salary,\r\n  s08.salary - s07.salary\r\nFROM\r\n  sample_07 s07 JOIN sample_08 s08\r\nON ( s07.code = s08.code)\r\nWHERE\r\n s07.salary < s08.salary\r\nORDER BY s08.salary-s07.salary DESC\r\nLIMIT 1000;\n"
      }
    }
  },
  {
    "name": "Sample: Top salary",
    "desc": "Top salary 2007 above $100k",
    "dialects": [],
    "data": {
      "query": {
        "statement": "SELECT sample_07.description, sample_07.salary\r\nFROM\r\n  sample_07\r\nWHERE\r\n( sample_07.salary > 100000)\r\nORDER BY sample_07.salary DESC\r\nLIMIT 1000"
      }
    }
  },
  {
    "name": "Sample: Salary growth",
    "desc": "Salary growth (sorted) from 2007-08",
    "dialects": [],
    "data": {
      "query": {
        "statement": "SELECT s07.description, s07.salary, s08.salary,\r\n  s08.salary - s07.salary\r\nFROM\r\n  sample_07 s07 JOIN sample_08 s08\r\nON ( s07.code = s08.code)\r\nWHERE\r\n s07.salary < s08.salary\r\nORDER BY s08.salary-s07.salary DESC\r\nLIMIT 1000"
      }
    }
  },
  {
    "name": "Sample: Job loss",
    "desc": "Job loss among the top earners 2007-08",
    "dialects": [],
    "data": {
      "query": {
        "statement": "SELECT s07.description, s07.total_emp, s08.total_emp, s07.salary\r\nFROM\r\n  sample_07 s07 JOIN \r\n  sample_08 s08\r\nON ( s07.code = s08.code )\r\nWHERE\r\n( s07.total_emp > s08.total_emp\r\n AND s07.salary > 100000 )\r\nORDER BY s07.salary DESC\nLIMIT 1000"
      }
    }
  },
  {
    "name": "US City Population",
    "desc": "Small samples of number of inhabitants in some US cities",
    "dialects": [
      "pheonix"
    ],
    "data": {
      "query": {
        "statement": "\nCREATE TABLE IF NOT EXISTS us_population (\n  state CHAR(2) NOT NULL,\n  city VARCHAR NOT NULL,\n  population BIGINT\n  CONSTRAINT my_pk PRIMARY KEY (state, city)\n);\n\n\nUPSERT INTO us_population VALUES ('NY','New York',8143197);\nUPSERT INTO us_population VALUES ('CA','Los Angeles',3844829);\nUPSERT INTO us_population VALUES ('IL','Chicago',2842518);\nUPSERT INTO us_population VALUES ('TX','Houston',2016582);\nUPSERT INTO us_population VALUES ('PA','Philadelphia',1463281);\nUPSERT INTO us_population VALUES ('AZ','Phoenix',1461575);\nUPSERT INTO us_population VALUES ('TX','San Antonio',1256509);\nUPSERT INTO us_population VALUES ('CA','San Diego',1255540);\nUPSERT INTO us_population VALUES ('TX','Dallas',1213825);\nUPSERT INTO us_population VALUES ('CA','San Jose',91233);\n\nSELECT\n  state as \"State\",\n  count(city) as \"City Count\",\n  sum(population) as \"Population Sum\"\nFROM\n  us_population\nGROUP BY\n  state\nORDER BY\n  sum(population) DESC\n;"
      }
    }
  },
  {
    "name": "Query and live display a live stream of data",
    "desc": "Simple select of auto generated data or via the user table backed by a Kafka topic",
    "dialects": [
      "flink"
    ],
    "data": {
      "query": {
        "statement": "\nCREATE TABLE datagen (\n  f_sequence INT,\n  f_random INT,\n  f_random_str STRING,\n  ts AS localtimestamp,\n  WATERMARK FOR ts AS ts\n) WITH (\n  'connector' = 'datagen',\n  'rows-per-second'='5',\n  'fields.f_sequence.kind'='sequence',\n  'fields.f_sequence.start'='1',\n  'fields.f_sequence.end'='1000',\n  'fields.f_random.min'='1',\n  'fields.f_random.max'='1000',\n  'fields.f_random_str.length'='10'\n)\n;\n\nSELECT *\nFROM datagen\nLIMIT 50\n;\n\n\n\nCREATE TABLE user_behavior (\n  user_id BIGINT,\n  item_id BIGINT,\n  category_id BIGINT,\n  behavior STRING,\n  ts TIMESTAMP(3),\n  proctime AS PROCTIME(),   -- generates processing-time attribute using computed column\n  WATERMARK FOR ts AS ts - INTERVAL '5' SECOND  -- defines watermark on ts column, marks ts as event-time attribute\n) WITH (\n  'connector' = 'kafka',  -- using kafka connector\n  'topic' = 'user_behavior',  -- kafka topic\n  'scan.startup.mode' = 'earliest-offset',  -- reading from the beginning\n  'properties.bootstrap.servers' = 'kafka:9094',  -- kafka broker address\n  'format' = 'json'  -- the data format is json\n)\n;\n\nSELECT * \nFROM user_behavior \nLIMIT 50\n;\n\n\nSELECT\n  HOUR(TUMBLE_START(ts, INTERVAL '1' HOUR)) as hour_of_day,\n  COUNT(*) as buy_cnt\nFROM\n  user_behavior\nWHERE\n  behavior = 'buy'\nGROUP BY\n  TUMBLE(ts, INTERVAL '1' HOUR)\n;\n  "
      }
    }
  },
  {
    "name": "New York Taxi dataset Analysis",
    "desc": "Regular SELECTs with custom Python UDF and create Machine Learning Model",
    "dialects": [
      "dasksql"
    ],
    "data": {
      "query": {
        "statement": "\nSELECT *\nFROM \"schema\".\"nyc-taxi\"\nLIMIT 100\n;\n\nSELECT\n    FLOOR(trip_distance / 5) * 5 AS \"distance\",\n    AVG(tip_amount) AS \"given tip\",\n    AVG(predict_price(total_amount, trip_distance, passenger_count)) AS \"predicted tip\"\nFROM \"nyc-taxi\"\nWHERE\n    trip_distance > 0 AND trip_distance < 50\nGROUP BY\n    FLOOR(trip_distance / 5) * 5\n;\n\nCREATE MODEL fare_estimator WITH (\n    model_class = 'sklearn.ensemble.GradientBoostingClassifier',\n    wrap_predict = True,\n    target_column = 'fare_amount'\n) AS (\n    SELECT trip_distance, fare_amount\n    FROM \"nyc-taxi\"\n    LIMIT 100\n)\n;\n"
      }
    }
  }
]